{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c89a1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "KERNEL_SIZE = 3\n",
    "NUM_CLASSES = 2 #313\n",
    "IMAGE_WIDTH = 128 #128\n",
    "IMAGE_HEIGHT = 128 #128\n",
    "SIGMA = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = r\"C:\\Users\\danie\\Desktop\\tiny rainbow.jpg\"\n",
    "image_folder = r\"C:\\Users\\danie\\Desktop\\just one photo\"\n",
    "image_pathway = r\"C:\\Users\\danie\\Desktop\\just one photo\\13.jpg\"\n",
    "\n",
    "TOO_SMALL = 2000\n",
    "SMALL = 500000\n",
    "MEDIUM = 1200000\n",
    "LARGE = 2100000\n",
    "    \n",
    "X_train = []\n",
    "Y_train = []\n",
    "counter = 1\n",
    "    \n",
    "height = 750\n",
    "width = 600\n",
    "\n",
    "epochs = 10 \n",
    "batch_size = 1 \n",
    "total_images = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, UpSampling2D, InputLayer\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage import data, io, color\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456de4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(img):\n",
    "    size = 0\n",
    "    resolution = img.shape[0] * img.shape[1]\n",
    "    if resolution <= TOO_SMALL:\n",
    "        size = 0\n",
    "    elif resolution <= SMALL:\n",
    "        size = 1\n",
    "    elif resolution <= MEDIUM:\n",
    "        size = 2\n",
    "    elif resolution <= LARGE:\n",
    "        size = 3\n",
    "    else:\n",
    "        size = 6\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(image_folder):\n",
    "    images = Path(image_folder).glob('*.jpg')\n",
    "\n",
    "    list_of_files = []\n",
    "    for image in images:\n",
    "        list_of_files.append(str(image))\n",
    "\n",
    "    df = pd. DataFrame(list_of_files, columns = [\"image_path\"])\n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    print(\"processing\", df_length, \"photos for training\")\n",
    "    \n",
    "    height_list= []\n",
    "    width_list = []\n",
    "    resolution = []\n",
    "    \n",
    "    for image_path in df['image_path']:\n",
    "        img = cv2.imread(str(image_path))\n",
    "        height_list.append(img.shape[0])\n",
    "        width_list.append(img.shape[1])\n",
    "        \n",
    "    df[\"height\"] = height_list\n",
    "    df[\"width\"] = width_list\n",
    "    df[\"resolution\"] = df[\"height\"] * df[\"width\"]\n",
    "    \n",
    "    df = df[df.resolution < LARGE]\n",
    "    \n",
    "    ll = df_length - len(df.index)\n",
    "    print(\"dropped \", ll, \"photos because they were too large to process\")\n",
    "    \n",
    "    df = df[df.resolution > TOO_SMALL]\n",
    "    \n",
    "    ss = df_length - len(df.index) - ll\n",
    "    print(\"dropped \", ss, \"photos because they were too small to process\")\n",
    "    df.head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_rgb(imgBGR, size): #imgRGB, size\n",
    "    b,g,r = cv2.split(imgBGR)\n",
    "    list_channels = [b,g,r]\n",
    "    \n",
    "    #check size first\n",
    "    if size ==1:\n",
    "        inverted_img = []\n",
    "        for c in list_channels:            \n",
    "            pca = PCA(n_components = 100)\n",
    "            transformed = pca.fit_transform(c/255) #r_scaled\n",
    "            inverted = pca.inverse_transform(transformed)\n",
    "            inverted_img.append(inverted)\n",
    "        \n",
    "        tuple(inverted_img)\n",
    "        RGB_compressed = cv2.merge(inverted_img)    \n",
    "\n",
    "    elif size == 2:\n",
    "        inverted_img = []\n",
    "        for c in list_channels:            \n",
    "            pca = PCA(n_components = 300)\n",
    "            transformed = pca.fit_transform(c/255) #r_scaled\n",
    "            inverted = pca.inverse_transform(transformed)\n",
    "            inverted_img.append(inverted)\n",
    "        \n",
    "        tuple(inverted_img)\n",
    "        RGB_compressed = cv2.merge(inverted_img)\n",
    "    else:\n",
    "        inverted_img = []\n",
    "        for c in list_channels:            \n",
    "            pca = PCA(n_components = 500)\n",
    "            transformed = pca.fit_transform(c/255) #r_scaled\n",
    "            inverted = pca.inverse_transform(transformed)\n",
    "            inverted_img.append(inverted)\n",
    "        \n",
    "        tuple(inverted_img)\n",
    "        RGB_compressed = cv2.merge(inverted_img)\n",
    "        \n",
    "    RGB_compressed = np.float32(RGB_compressed)\n",
    "    print(\"PCA SHAPE\",np.min(RGB_compressed),np.max(RGB_compressed))    \n",
    "    return RGB_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc603337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_pad(image):\n",
    "    \n",
    "    img_height = image.shape[0]\n",
    "    print(height)\n",
    "    img_width = image.shape[1]\n",
    "    print(width)\n",
    "    \n",
    "    WHITE = [255,255,255] #[255,255,255]  1, 1, 1\n",
    "    \n",
    "    if img_height % 2 == 0:\n",
    "        top = int((height - img_height)/ 2)\n",
    "        bottom = int((height - img_height)/ 2)\n",
    "    else: \n",
    "        top = int((height - (img_height-1))/ 2)\n",
    "        bottom = int(((height - (img_height-1))/ 2)-1)\n",
    "\n",
    "    if img_width % 2 == 0:\n",
    "        left = int((width - img_width)/ 2)\n",
    "        right = int((width - img_width)/ 2)\n",
    "    else: \n",
    "        left = int((width - (img_width-1))/ 2)\n",
    "        right = int(((width - (img_width-1))/2)-1)\n",
    "    \n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT,value=WHITE)\n",
    "    print(image.shape)\n",
    "    print(np.min(image),np.max(image))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0e9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97bcc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, UpSampling2D\n",
    "\n",
    "\n",
    "\n",
    "def mode():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "    Conv2D(32, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(32, kernel_size=KERNEL_SIZE, activation='relu', padding='same', strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=KERNEL_SIZE, activation='relu', padding='same', strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=KERNEL_SIZE, activation='relu', padding='same', strides=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same', dilation_rate=2),\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same', dilation_rate=2),\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same', dilation_rate=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same', dilation_rate=2),\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same', dilation_rate=2),\n",
    "    Conv2D(256, kernel_size=KERNEL_SIZE, activation='relu', padding='same', dilation_rate=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    UpSampling2D(size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=KERNEL_SIZE, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(NUM_CLASSES, kernel_size=1, padding='same'), UpSampling2D(size=(4, 4))\n",
    "        ])\n",
    "    \n",
    "    model.compile(optimizer =\"adam\", loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baeb2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "330716bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71aa964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((1,128,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea1f198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_184 (Conv2D)         (1, 128, 128, 32)         320       \n",
      "                                                                 \n",
      " conv2d_185 (Conv2D)         (1, 64, 64, 32)           9248      \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (1, 64, 64, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_186 (Conv2D)         (1, 64, 64, 64)           18496     \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (1, 32, 32, 64)           36928     \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (1, 32, 32, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (1, 32, 32, 128)          73856     \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (1, 32, 32, 128)          147584    \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (1, 16, 16, 128)          147584    \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (1, 16, 16, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (1, 16, 16, 256)          295168    \n",
      "                                                                 \n",
      " conv2d_192 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (1, 16, 16, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (1, 16, 16, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " conv2d_198 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (1, 16, 16, 256)          590080    \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (1, 16, 16, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_200 (Conv2D)         (1, 16, 16, 128)          295040    \n",
      "                                                                 \n",
      " conv2d_201 (Conv2D)         (1, 16, 16, 128)          147584    \n",
      "                                                                 \n",
      " conv2d_202 (Conv2D)         (1, 16, 16, 128)          147584    \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (1, 16, 16, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (1, 32, 32, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_203 (Conv2D)         (1, 32, 32, 64)           73792     \n",
      "                                                                 \n",
      " conv2d_204 (Conv2D)         (1, 32, 32, 64)           36928     \n",
      "                                                                 \n",
      " conv2d_205 (Conv2D)         (1, 32, 32, 64)           36928     \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (1, 32, 32, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (1, 32, 32, 2)            130       \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (1, 128, 128, 2)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,192,546\n",
      "Trainable params: 6,190,178\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8a229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d4897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
