{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def init():\n",
    "    #CHANGE THIS TO YOUR TRAIN FOLDER\n",
    "image_folder = 'C:/Study/Semester2/Machine Learning/ML_images/Training' \n",
    "#image_folder = 'C:/Users/danie/Desktop/Training_ML'\n",
    "\n",
    "TOO_SMALL = 200000\n",
    "SMALL = 500000\n",
    "MEDIUM = 1200000\n",
    "LARGE = 2100000\n",
    "    \n",
    "X_train = []\n",
    "Y_train = []\n",
    "counter = 1\n",
    "    \n",
    "img_height = 1888 #Usually 128. this might change depending on Annaya & Danielle's input \n",
    "img_width = 1888 #Usually 128. this might change depending on Annaya & Danielle's input \n",
    "epochs = 10 #Start with 1, and increase to 10, 100, 500, 1000 and 3000. 11 is the recommended number of runs through the training dataset. We will probably have to tune this. \n",
    "#total_training = total number of training data len()\n",
    "batch_size = 1 #test different ones from 1 to 2, 5, 10, etc\n",
    "total_images = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "6ba26cc8e50f49b5b9b751f88421f6cc",
    "deepnote_cell_height": 459,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10265,
    "execution_start": 1652547014086,
    "source_hash": "25a5d69b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, UpSampling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage import data, io,color\n",
    "from skimage.io import imread_collection #loads a collection of images\n",
    "from skimage.io import imread, imshow\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "5647a315e91e408b8dcdd46d33814f9e",
    "deepnote_cell_height": 477,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1652547146694,
    "source_hash": "8fbce57",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define sizes of images based on their resolution\n",
    "#Image shape and resolution\n",
    "\n",
    "#TODO make the IMG sizes make sense\n",
    "\n",
    "\n",
    "def shape(img):\n",
    "    size = 0\n",
    "    resolution = img.shape[0] * img.shape[1]\n",
    "    if resolution <= TOO_SMALL:\n",
    "        size = 0\n",
    "    elif resolution <= SMALL:\n",
    "        size = 1\n",
    "    elif resolution <= MEDIUM:\n",
    "        size = 2\n",
    "    elif resolution <= LARGE:\n",
    "        size = 3\n",
    "    else:\n",
    "        size = 6\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(image_folder):\n",
    "    images = Path(image_folder).glob('*.jpg')\n",
    "\n",
    "    list_of_files = []\n",
    "    for image in images:\n",
    "        list_of_files.append(str(image))\n",
    "\n",
    "    df = pd. DataFrame(list_of_files, columns = [\"image_path\"])\n",
    "    df_length = len(df.index)\n",
    "    print(\"processing\", df_length, \"photos for training\")\n",
    "    \n",
    "    height= []\n",
    "    width = []\n",
    "    resolution = []\n",
    "    \n",
    "    for image_path in df['image_path']:\n",
    "        img = cv2.imread(str(image_path))\n",
    "        height.append(img.shape[0])\n",
    "        width.append(img.shape[1])\n",
    "        \n",
    "    df[\"height\"] = height\n",
    "    df[\"width\"] = width\n",
    "    df[\"resolution\"] = df[\"height\"] * df[\"width\"]\n",
    "    \n",
    "    df = df[df.resolution < LARGE]\n",
    "    \n",
    "    ll = df_length - len(df.index)\n",
    "    print(\"dropped \", ll, \"photos because they were too large to process\")\n",
    "    \n",
    "    df = df[df.resolution > TOO_SMALL]\n",
    "    \n",
    "    ss = df_length - len(df.index) - ll\n",
    "    print(\"dropped \", ss, \"photos because they were too small to process\")\n",
    "    df.head()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "284e594fca804177bb7508f8e816bfa2",
    "deepnote_cell_height": 387,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1652547146695,
    "source_hash": "4c92008b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#PCA rgb then pass to prep_img as an rgb image\n",
    "\n",
    "def pca_rgb(imgBGR, size): #imgRGB, size\n",
    "    b,g,r = cv2.split(imgBGR)\n",
    "    list_channels = [b,g,r]\n",
    "    \n",
    "    #check size first\n",
    "    if size ==1:\n",
    "        inverted_img = []\n",
    "        for c in list_channels:            \n",
    "            pca = PCA(n_components = 100)\n",
    "            transformed = pca.fit_transform(c/255) #r_scaled\n",
    "            inverted = pca.inverse_transform(transformed)\n",
    "            inverted_img.append(inverted)\n",
    "        \n",
    "        tuple(inverted_img)\n",
    "        RGB_compressed = cv2.merge(inverted_img)    \n",
    "\n",
    "    elif size == 2:\n",
    "        inverted_img = []\n",
    "        for c in list_channels:            \n",
    "            pca = PCA(n_components = 300)\n",
    "            transformed = pca.fit_transform(c/255) #r_scaled\n",
    "            inverted = pca.inverse_transform(transformed)\n",
    "            inverted_img.append(inverted)\n",
    "        \n",
    "        tuple(inverted_img)\n",
    "        RGB_compressed = cv2.merge(inverted_img)\n",
    "    else:\n",
    "        inverted_img = []\n",
    "        for c in list_channels:            \n",
    "            pca = PCA(n_components = 500)\n",
    "            transformed = pca.fit_transform(c/255) #r_scaled\n",
    "            inverted = pca.inverse_transform(transformed)\n",
    "            inverted_img.append(inverted)\n",
    "        \n",
    "        tuple(inverted_img)\n",
    "        RGB_compressed = cv2.merge(inverted_img)\n",
    "        \n",
    "    RGB_compressed = np.float32(RGB_compressed)\n",
    "        \n",
    "    return RGB_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image padding\n",
    "\n",
    "def rgb_pad(image):\n",
    "    \n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    WHITE = [255,255,255] #[255,255,255]  1, 1, 1\n",
    "    MAX = 1888\n",
    "    \n",
    "    if height % 2 == 0:\n",
    "        top = int((MAX - height)/ 2)\n",
    "        bottom = int((MAX - height)/ 2)\n",
    "    else: \n",
    "        top = int((MAX - (height-1))/ 2)\n",
    "        bottom = int(((MAX - (height-1))/ 2)-1)\n",
    "\n",
    "    if width % 2 == 0:\n",
    "        left = int((MAX - width)/ 2)\n",
    "        right = int((MAX - width)/ 2)\n",
    "    else: \n",
    "        left = int((MAX - (width-1))/ 2)\n",
    "        right = int(((MAX - (width-1))/2)-1)\n",
    "    \n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right,\n",
    "    cv2.BORDER_CONSTANT,value=WHITE)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cell_id": "6be9a9aec0ee44dab9bb55d664de627f",
    "deepnote_cell_height": 693,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1652547146783,
    "source_hash": "c4f5421",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Debugged function\n",
    "def prep_img(img_path):\n",
    "    imgRGB = img_to_array(load_img(img_path))\n",
    "    imgRGB = np.array(imgRGB, dtype=float)\n",
    "\n",
    "    \n",
    "    #check the image category by 'shape' function\n",
    "    image_size_category = shape(imgRGB) \n",
    "    #print(\"image size determined!\")\n",
    "\n",
    "    if image_size_category <1:\n",
    "        raise Exception(\"Your image is too small to be used\")\n",
    "    elif image_size_category >4:\n",
    "        raise Exception(\"Your image is too big to be used\")\n",
    "\n",
    "    #print(\"image PCA started!\")\n",
    " \n",
    "    RGB_compressed = pca_rgb(imgRGB, image_size_category) \n",
    "    print('RGB_compressed:', np.min(RGB_compressed), np.max(RGB_compressed))\n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(RGB_compressed)\n",
    "    \n",
    "    print(\"image is padded\")\n",
    "    padded_image = rgb_pad(RGB_compressed)\n",
    "  \n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(padded_image) # show after rgb compressed after padded\n",
    "    \n",
    "    #image_pca = np.float32((1.0/255)*image_pca) # #The rgb_compressed come out in RGB scaled data already\n",
    "    print(\"image converted to LAB\")\n",
    "    padded_LAB = cv2.cvtColor(padded_image, cv2.COLOR_RGB2Lab) #convert padded RGB compressed to LAB\n",
    "    print('A:', np.min(padded_LAB), np.max(padded_LAB))\n",
    "    \n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(padded_image, cmap = plt.cm.gray) #show after convert padded rgb compressed to RGB with the function\n",
    "    #imgLAB = np.clip(imgLAB, 0, 1)\n",
    "\n",
    "    \n",
    "    #separate L and AB color channels\n",
    "    Y = padded_LAB[:, :,1:]\n",
    "    Y = Y / 128 #comment out when show predicted\n",
    "    print('A normalized:', np.min(Y[:,:,0]), np.max(Y[:,:,0]))\n",
    "    print('B normalized:', np.min(Y[:,:,0]), np.max(Y[:,:,0]))\n",
    "    \n",
    "    X = padded_LAB[:, :, 0] \n",
    "    print('X:', np.min(X), np.max(X))\n",
    "    #plt.figure(figsize=(10, 10)) # show converted RGB to L channel \n",
    "    #plt.imshow(X)\n",
    "    \n",
    "    #this is in sample code and idk why\n",
    "    \n",
    "    X = X.reshape(1, 1888, 1888, 1) #comment out when show predicted\n",
    "    Y = Y.reshape(1, 1888, 1888, 2) #comment out when show predicted\n",
    "    \n",
    "    print(\"image processed\")\n",
    "\n",
    "    return Y, X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataframe(df):\n",
    "    for index, row in df.iterrows():\n",
    "        Y, X = prep_img(row[\"image_path\"])\n",
    "        Y_train.append(Y)\n",
    "        X_train.append(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the code below to process ALL photos and feed them to the model!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 151 photos for training\n",
      "dropped  9 photos because they were too large to process\n",
      "dropped  5 photos because they were too small to process\n",
      "RGB_compressed: 0.0074463133 0.9853132\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -42.5 100.0\n",
      "A: -0.21948242 0.3572998\n",
      "B: -0.21948242 0.3572998\n",
      "X: 0.8605957 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.17393492 1.1337924\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -47.359375 100.0\n",
      "A: -0.29858398 0.60058594\n",
      "B: -0.29858398 0.60058594\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.021102002 1.022073\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -49.703125 100.0\n",
      "A: -0.19250488 0.30078125\n",
      "B: -0.19250488 0.30078125\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0751553 1.050764\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -28.59375 100.0\n",
      "A: -0.22338867 0.38256836\n",
      "B: -0.22338867 0.38256836\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.018501235 1.0222906\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -31.25 100.0\n",
      "A: -0.24414062 0.29248047\n",
      "B: -0.24414062 0.29248047\n",
      "X: 0.012207031 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.047817856 1.0379268\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -29.15625 100.0\n",
      "A: -0.14587402 0.19055176\n",
      "B: -0.14587402 0.19055176\n",
      "X: 0.061035156 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.01348307 1.019338\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -32.34375 100.0\n",
      "A: -0.24902344 0.37268066\n",
      "B: -0.24902344 0.37268066\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.023284195 1.0285105\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -66.78125 100.0\n",
      "A: -0.36535645 0.39123535\n",
      "B: -0.36535645 0.39123535\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0064722444 1.017586\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -51.484375 100.0\n",
      "A: -0.22998047 0.3330078\n",
      "B: -0.22998047 0.3330078\n",
      "X: 0.17089844 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.111952186 1.0785731\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -31.546875 100.0\n",
      "A: -0.11376953 0.17114258\n",
      "B: -0.11376953 0.17114258\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.10434853 1.0352584\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -15.71875 100.0\n",
      "A: -0.122802734 0.32592773\n",
      "B: -0.122802734 0.32592773\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.055566095 1.0637736\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -39.09375 100.0\n",
      "A: -0.30541992 0.62280273\n",
      "B: -0.30541992 0.62280273\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.050888456 1.0533159\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -41.484375 100.0\n",
      "A: -0.2562256 0.46020508\n",
      "B: -0.2562256 0.46020508\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.028297005 1.0268323\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -35.90625 100.0\n",
      "A: -0.12390137 0.22363281\n",
      "B: -0.12390137 0.22363281\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0057959966 1.0105445\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -35.984375 100.0\n",
      "A: -0.18701172 0.25134277\n",
      "B: -0.18701172 0.25134277\n",
      "X: 0.3540039 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.089672014 1.0451066\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -29.0 100.0\n",
      "A: -0.19213867 0.26391602\n",
      "B: -0.19213867 0.26391602\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0375014 1.0606626\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -30.796875 100.0\n",
      "A: -0.14587402 0.34936523\n",
      "B: -0.14587402 0.34936523\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.040709503 1.0602098\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -34.671875 100.0\n",
      "A: -0.27087402 0.46142578\n",
      "B: -0.27087402 0.46142578\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.049866755 1.0296894\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -25.25 100.0\n",
      "A: -0.17834473 0.2989502\n",
      "B: -0.17834473 0.2989502\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.015473533 1.007293\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -17.65625 100.0\n",
      "A: -0.10620117 0.35266113\n",
      "B: -0.10620117 0.35266113\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.056643132 1.0761348\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -14.625 100.0\n",
      "A: -0.10925293 0.2944336\n",
      "B: -0.10925293 0.2944336\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.022652961 1.0276538\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -17.296875 100.0\n",
      "A: -0.13513184 0.20202637\n",
      "B: -0.13513184 0.20202637\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.023447834 1.0301744\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -36.453125 100.0\n",
      "A: -0.28479004 0.5827637\n",
      "B: -0.28479004 0.5827637\n",
      "X: 0.018310547 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.030260554 1.0192668\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -56.21875 100.0\n",
      "A: -0.43920898 0.5435791\n",
      "B: -0.43920898 0.5435791\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.1255438 1.0786119\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -44.71875 100.0\n",
      "A: -0.25463867 0.5181885\n",
      "B: -0.25463867 0.5181885\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.020862296 1.0254154\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -48.140625 100.0\n",
      "A: -0.31115723 0.45703125\n",
      "B: -0.31115723 0.45703125\n",
      "X: 0.06713867 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.05080834 1.0456443\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -75.015625 100.0\n",
      "A: -0.39831543 0.52124023\n",
      "B: -0.39831543 0.52124023\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.031488415 1.0325478\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -52.84375 100.0\n",
      "A: -0.23388672 0.3873291\n",
      "B: -0.23388672 0.3873291\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: 0.00920689 1.0029134\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -26.609375 100.0\n",
      "A: -0.12219238 0.33789062\n",
      "B: -0.12219238 0.33789062\n",
      "X: 2.6550293 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0830307 1.0323005\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -83.59375 100.0\n",
      "A: -0.3380127 0.6179199\n",
      "B: -0.3380127 0.6179199\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.013850404 1.0100958\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -70.484375 100.0\n",
      "A: -0.19592285 0.5192871\n",
      "B: -0.19592285 0.5192871\n",
      "X: 0.37841797 100.0\n",
      "image processed\n",
      "RGB_compressed: 0.0027107731 1.0336168\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -48.484375 100.0\n",
      "A: -0.07751465 0.23828125\n",
      "B: -0.07751465 0.23828125\n",
      "X: 3.2287598 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04329145 1.0466982\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -49.96875 100.0\n",
      "A: -0.24584961 0.3388672\n",
      "B: -0.24584961 0.3388672\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.024690967 1.0194483\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -38.9375 100.0\n",
      "A: -0.30419922 0.40734863\n",
      "B: -0.30419922 0.40734863\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.033332556 1.029418\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -50.984375 100.0\n",
      "A: -0.3404541 0.23620605\n",
      "B: -0.3404541 0.23620605\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.07759527 1.1167668\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -34.65625 100.0\n",
      "A: -0.23864746 0.4979248\n",
      "B: -0.23864746 0.4979248\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0532002 1.0563098\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -71.984375 100.0\n",
      "A: -0.41918945 0.40844727\n",
      "B: -0.41918945 0.40844727\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.030453177 1.1223093\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -16.421875 100.0\n",
      "A: -0.07800293 0.28222656\n",
      "B: -0.07800293 0.28222656\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.032409754 1.041111\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -52.96875 100.0\n",
      "A: -0.41381836 0.5001221\n",
      "B: -0.41381836 0.5001221\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.052344795 1.0431812\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -22.78125 100.0\n",
      "A: -0.17797852 0.22827148\n",
      "B: -0.17797852 0.22827148\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06665258 1.1286579\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -72.515625 100.0\n",
      "A: -0.3725586 0.52697754\n",
      "B: -0.3725586 0.52697754\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04262356 1.05215\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -49.859375 100.0\n",
      "A: -0.38952637 0.4473877\n",
      "B: -0.38952637 0.4473877\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.054364093 1.045965\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -38.0625 100.0\n",
      "A: -0.17285156 0.32958984\n",
      "B: -0.17285156 0.32958984\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.062587775 1.0605912\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -26.71875 100.0\n",
      "A: -0.20874023 0.2133789\n",
      "B: -0.20874023 0.2133789\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.033666935 1.0362058\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -44.34375 100.0\n",
      "A: -0.2581787 0.33703613\n",
      "B: -0.2581787 0.33703613\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.035740335 1.029763\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -39.03125 100.0\n",
      "A: -0.13623047 0.19433594\n",
      "B: -0.13623047 0.19433594\n",
      "X: 0.0 100.0\n",
      "image processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB_compressed: -0.10807131 1.1213304\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -52.890625 100.0\n",
      "A: -0.30895996 0.30322266\n",
      "B: -0.30895996 0.30322266\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.029292095 1.0299101\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -21.5625 100.0\n",
      "A: -0.16491699 0.39611816\n",
      "B: -0.16491699 0.39611816\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.070702076 1.0824528\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -63.828125 100.0\n",
      "A: -0.45251465 0.54833984\n",
      "B: -0.45251465 0.54833984\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0286018 1.032088\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -58.4375 100.0\n",
      "A: -0.34387207 0.3112793\n",
      "B: -0.34387207 0.3112793\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.038568106 1.0246221\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -27.96875 100.0\n",
      "A: -0.1418457 0.2902832\n",
      "B: -0.1418457 0.2902832\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.049552802 1.0552194\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -39.28125 100.0\n",
      "A: -0.30688477 0.3955078\n",
      "B: -0.30688477 0.3955078\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.064843304 1.0669851\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -55.703125 100.0\n",
      "A: -0.43518066 0.58117676\n",
      "B: -0.43518066 0.58117676\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.030401355 1.0403188\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -25.453125 100.0\n",
      "A: -0.19885254 0.30249023\n",
      "B: -0.19885254 0.30249023\n",
      "X: 0.1586914 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.016972871 1.0143961\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -50.046875 100.0\n",
      "A: -0.3909912 0.35754395\n",
      "B: -0.3909912 0.35754395\n",
      "X: 0.99487305 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.03417947 1.0466855\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -25.859375 100.0\n",
      "A: -0.20202637 0.383667\n",
      "B: -0.20202637 0.383667\n",
      "X: 0.04272461 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06173125 1.0623726\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -36.578125 100.0\n",
      "A: -0.25598145 0.44677734\n",
      "B: -0.25598145 0.44677734\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.08867403 1.0784373\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -73.046875 100.0\n",
      "A: -0.5706787 0.586792\n",
      "B: -0.5706787 0.586792\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.003219833 1.0007464\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -17.03125 100.0\n",
      "A: -0.13305664 0.30334473\n",
      "B: -0.13305664 0.30334473\n",
      "X: 0.06713867 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0730953 1.0909568\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -26.328125 100.0\n",
      "A: -0.11755371 0.34191895\n",
      "B: -0.11755371 0.34191895\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04321519 1.0422862\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -39.125 100.0\n",
      "A: -0.13500977 0.31445312\n",
      "B: -0.13500977 0.31445312\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.01757653 1.0222548\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -44.578125 100.0\n",
      "A: -0.26098633 0.32958984\n",
      "B: -0.26098633 0.32958984\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.032125812 1.0368081\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -50.203125 100.0\n",
      "A: -0.32922363 0.40356445\n",
      "B: -0.32922363 0.40356445\n",
      "X: 0.1586914 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.019965429 1.0185362\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -53.125 100.0\n",
      "A: -0.2454834 0.29309082\n",
      "B: -0.2454834 0.29309082\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04797037 1.0644926\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -65.125 100.0\n",
      "A: -0.31347656 0.42114258\n",
      "B: -0.31347656 0.42114258\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.1064249 1.0876573\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -58.53125 100.0\n",
      "A: -0.32788086 0.5839844\n",
      "B: -0.32788086 0.5839844\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.111687675 1.1345005\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -91.21875 100.0\n",
      "A: -0.40698242 0.52246094\n",
      "B: -0.40698242 0.52246094\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.028431132 1.0585827\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -33.9375 100.0\n",
      "A: -0.15344238 0.20788574\n",
      "B: -0.15344238 0.20788574\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.070783995 1.0732323\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -67.1875 100.0\n",
      "A: -0.32861328 0.5377197\n",
      "B: -0.32861328 0.5377197\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0658117 1.0865684\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -94.9375 100.0\n",
      "A: -0.6085205 0.66711426\n",
      "B: -0.6085205 0.66711426\n",
      "X: 5.932617 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.019495737 1.010207\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -29.28125 100.0\n",
      "A: -0.17382812 0.32348633\n",
      "B: -0.17382812 0.32348633\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.08409631 1.0847732\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -78.34375 100.0\n",
      "A: -0.34887695 0.5505371\n",
      "B: -0.34887695 0.5505371\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.07913512 1.0697092\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -59.9375 100.0\n",
      "A: -0.27954102 0.3602295\n",
      "B: -0.27954102 0.3602295\n",
      "X: 0.3479004 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.08267004 1.0771812\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -87.5 100.0\n",
      "A: -0.48706055 0.6069336\n",
      "B: -0.48706055 0.6069336\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.16100927 1.1814651\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -97.1875 100.0\n",
      "A: -0.56396484 0.66223145\n",
      "B: -0.56396484 0.66223145\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.097764105 1.1405029\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -71.046875 100.0\n",
      "A: -0.39916992 0.42834473\n",
      "B: -0.39916992 0.42834473\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.08627394 1.0633478\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -69.46875 100.0\n",
      "A: -0.52441406 0.36376953\n",
      "B: -0.52441406 0.36376953\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.051365305 1.0376738\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -54.46875 100.0\n",
      "A: -0.24645996 0.57092285\n",
      "B: -0.24645996 0.57092285\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.12701607 1.121343\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -80.34375 100.0\n",
      "A: -0.30078125 0.4038086\n",
      "B: -0.30078125 0.4038086\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.11274336 1.0496963\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -105.4375 100.0\n",
      "A: -0.47387695 0.5875244\n",
      "B: -0.47387695 0.5875244\n",
      "X: 0.92163086 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.01794591 1.0190146\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -32.484375 100.0\n",
      "A: -0.23156738 0.5130615\n",
      "B: -0.23156738 0.5130615\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.073256865 1.0702873\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -41.1875 100.0\n",
      "A: -0.32177734 0.41223145\n",
      "B: -0.32177734 0.41223145\n",
      "X: 0.29296875 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0540815 1.0498822\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -51.140625 100.0\n",
      "A: -0.26159668 0.29296875\n",
      "B: -0.26159668 0.29296875\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.016955318 1.0157987\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -34.8125 100.0\n",
      "A: -0.27197266 0.42590332\n",
      "B: -0.27197266 0.42590332\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.044396695 1.031195\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -35.03125 100.0\n",
      "A: -0.1237793 0.4099121\n",
      "B: -0.1237793 0.4099121\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.05107369 1.0649081\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -53.828125 100.0\n",
      "A: -0.15063477 0.34423828\n",
      "B: -0.15063477 0.34423828\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0397807 1.0333954\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -68.8125 100.0\n",
      "A: -0.38256836 0.35253906\n",
      "B: -0.38256836 0.35253906\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.0089813955 1.0176119\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -22.8125 100.0\n",
      "A: -0.115478516 0.21972656\n",
      "B: -0.115478516 0.21972656\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.053410307 1.020753\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -67.421875 100.0\n",
      "A: -0.14489746 0.55322266\n",
      "B: -0.14489746 0.55322266\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.17858653 1.1335334\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -35.015625 100.0\n",
      "A: -0.21081543 0.3564453\n",
      "B: -0.21081543 0.3564453\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.026938729 1.0262741\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -64.875 100.0\n",
      "A: -0.37023926 0.5489502\n",
      "B: -0.37023926 0.5489502\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04912708 1.0592016\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -56.671875 100.0\n",
      "A: -0.44274902 0.5876465\n",
      "B: -0.44274902 0.5876465\n",
      "X: 0.018310547 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04412944 1.0539718\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -33.28125 100.0\n",
      "A: -0.26000977 0.35339355\n",
      "B: -0.26000977 0.35339355\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.14056867 1.125363\n",
      "image is padded\n",
      "image converted to LAB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: -38.65625 100.0\n",
      "A: -0.30200195 0.33728027\n",
      "B: -0.30200195 0.33728027\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.04936067 1.0432223\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -41.5 100.0\n",
      "A: -0.25024414 0.3701172\n",
      "B: -0.25024414 0.3701172\n",
      "X: 0.12207031 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.024087714 1.0525559\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -100.3125 100.0\n",
      "A: -0.57299805 0.5821533\n",
      "B: -0.57299805 0.5821533\n",
      "X: 0.20141602 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.09928114 1.0789912\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -64.859375 100.0\n",
      "A: -0.42980957 0.59350586\n",
      "B: -0.42980957 0.59350586\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.09920036 1.1028641\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -96.3125 100.0\n",
      "A: -0.6604004 0.70288086\n",
      "B: -0.6604004 0.70288086\n",
      "X: 0.4272461 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.056639176 1.0446461\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -48.96875 100.0\n",
      "A: -0.3059082 0.41381836\n",
      "B: -0.3059082 0.41381836\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.05082616 1.0502896\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -40.171875 100.0\n",
      "A: -0.19226074 0.32019043\n",
      "B: -0.19226074 0.32019043\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.005801904 1.005066\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -40.203125 100.0\n",
      "A: -0.17370605 0.34838867\n",
      "B: -0.17370605 0.34838867\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06430512 1.0734742\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -50.09375 100.0\n",
      "A: -0.39135742 0.5456543\n",
      "B: -0.39135742 0.5456543\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.037271336 1.0332421\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -58.421875 100.0\n",
      "A: -0.20239258 0.5085449\n",
      "B: -0.20239258 0.5085449\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.037883632 1.0553025\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -71.359375 100.0\n",
      "A: -0.20458984 0.56103516\n",
      "B: -0.20458984 0.56103516\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.03414375 1.0242779\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -67.21875 100.0\n",
      "A: -0.28027344 0.43188477\n",
      "B: -0.28027344 0.43188477\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.05064658 1.0331337\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -60.5625 100.0\n",
      "A: -0.32250977 0.40698242\n",
      "B: -0.32250977 0.40698242\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.040164966 1.031487\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -57.53125 100.0\n",
      "A: -0.3265381 0.4053955\n",
      "B: -0.3265381 0.4053955\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.03419453 1.0245591\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -66.921875 100.0\n",
      "A: -0.52282715 0.4539795\n",
      "B: -0.52282715 0.4539795\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.07398607 1.0591981\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -55.25 100.0\n",
      "A: -0.22924805 0.3503418\n",
      "B: -0.22924805 0.3503418\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.033752568 1.0451751\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -53.59375 100.0\n",
      "A: -0.27697754 0.46984863\n",
      "B: -0.27697754 0.46984863\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06421078 1.0554188\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -19.734375 100.0\n",
      "A: -0.1541748 0.46374512\n",
      "B: -0.1541748 0.46374512\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.09513417 1.0830058\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -76.203125 100.0\n",
      "A: -0.38928223 0.4124756\n",
      "B: -0.38928223 0.4124756\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.073244475 1.0720255\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -65.453125 100.0\n",
      "A: -0.25061035 0.39257812\n",
      "B: -0.25061035 0.39257812\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.054521475 1.0681767\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -86.265625 100.0\n",
      "A: -0.30895996 0.52404785\n",
      "B: -0.30895996 0.52404785\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.080773726 1.0735779\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -74.25 100.0\n",
      "A: -0.4260254 0.52453613\n",
      "B: -0.4260254 0.52453613\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.05645618 1.0731492\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -71.515625 100.0\n",
      "A: -0.33166504 0.49206543\n",
      "B: -0.33166504 0.49206543\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.028448518 1.0441312\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -55.84375 100.0\n",
      "A: -0.22705078 0.5477295\n",
      "B: -0.22705078 0.5477295\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.11552019 1.0812545\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -62.15625 100.0\n",
      "A: -0.31677246 0.6678467\n",
      "B: -0.31677246 0.6678467\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.079884194 1.0998182\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -24.140625 100.0\n",
      "A: -0.18859863 0.55041504\n",
      "B: -0.18859863 0.55041504\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.09932376 1.0662075\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -52.578125 100.0\n",
      "A: -0.22241211 0.34094238\n",
      "B: -0.22241211 0.34094238\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.14902426 1.1420048\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -43.671875 100.0\n",
      "A: -0.27087402 0.31481934\n",
      "B: -0.27087402 0.31481934\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.16502158 1.1535705\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -52.109375 100.0\n",
      "A: -0.33081055 0.5118408\n",
      "B: -0.33081055 0.5118408\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.1012699 1.1715369\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -61.703125 100.0\n",
      "A: -0.44799805 0.5283203\n",
      "B: -0.44799805 0.5283203\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.058601983 1.0603944\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -34.21875 100.0\n",
      "A: -0.23742676 0.5168457\n",
      "B: -0.23742676 0.5168457\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.061993595 1.0664065\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -37.203125 100.0\n",
      "A: -0.2906494 0.4255371\n",
      "B: -0.2906494 0.4255371\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.016635476 1.0377313\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -47.984375 100.0\n",
      "A: -0.3109131 0.5410156\n",
      "B: -0.3109131 0.5410156\n",
      "X: 2.7954102 100.0\n",
      "image processed\n",
      "RGB_compressed: 0.048052583 1.0082833\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -27.421875 100.0\n",
      "A: -0.2142334 0.25317383\n",
      "B: -0.2142334 0.25317383\n",
      "X: 5.1757812 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.02626646 1.0251071\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -26.859375 100.0\n",
      "A: -0.17871094 0.54089355\n",
      "B: -0.17871094 0.54089355\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.07254792 0.9722454\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -29.8125 100.0\n",
      "A: -0.20373535 0.43322754\n",
      "B: -0.20373535 0.43322754\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.053079184 1.0433385\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -43.171875 100.0\n",
      "A: -0.11608887 0.5262451\n",
      "B: -0.11608887 0.5262451\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.011183734 1.0149671\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -28.484375 100.0\n",
      "A: -0.18432617 0.3466797\n",
      "B: -0.18432617 0.3466797\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06418998 1.0700706\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -40.265625 100.0\n",
      "A: -0.26306152 0.491333\n",
      "B: -0.26306152 0.491333\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.030727252 1.0253545\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -43.21875 100.0\n",
      "A: -0.30822754 0.5175781\n",
      "B: -0.30822754 0.5175781\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06405002 1.0569336\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -48.75 100.0\n",
      "A: -0.38085938 0.53271484\n",
      "B: -0.38085938 0.53271484\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.06660052 1.0606436\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -54.984375 100.0\n",
      "A: -0.42956543 0.6185303\n",
      "B: -0.42956543 0.6185303\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.029711708 1.0289633\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -25.046875 100.0\n",
      "A: -0.19567871 0.47045898\n",
      "B: -0.19567871 0.47045898\n",
      "X: 0.0 100.0\n",
      "image processed\n",
      "RGB_compressed: -0.022815673 1.0220758\n",
      "image is padded\n",
      "image converted to LAB\n",
      "A: -24.59375 100.0\n",
      "A: -0.19213867 0.42419434\n",
      "B: -0.19213867 0.42419434\n",
      "X: 0.0 100.0\n",
      "image processed\n"
     ]
    }
   ],
   "source": [
    "df = create_dataframe(image_folder)\n",
    "prep_dataframe(df)\n",
    "\n",
    "#add padd(image).tolist()\n",
    "#caused TypeError: unsupported operand type(s) for /: 'list' and 'int'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(): \n",
    "    model1 = Sequential([\n",
    "        #encoder\n",
    "        Conv2D(128, 2, strides = 2, padding = \"same\", activation = \"relu\", input_shape= (1888, 1888, 1)), #testing shape changes\n",
    "        Conv2D(256, 2, strides = 2, padding = \"same\", activation = \"relu\"), \n",
    "        Conv2D(256, 2, strides = 2, padding = \"same\", activation = \"relu\"), #first param to 512\n",
    "\n",
    "        #decoder\n",
    "        Conv2D(256, 2, padding = \"same\", activation = \"relu\"), \n",
    "        UpSampling2D(2),\n",
    "        Conv2D(128, 2, padding = \"same\", activation = \"relu\"), \n",
    "        UpSampling2D(2), \n",
    "        Conv2D(2, 2, padding = \"same\", activation = \"tanh\"),\n",
    "        UpSampling2D(2),\n",
    "    ])\n",
    "    model1.compile(optimizer =\"adam\", loss = \"mse\", metrics = [\"accuracy\"])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 944, 944, 128)     640       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 472, 472, 256)     131328    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 236, 236, 256)     262400    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 236, 236, 256)     262400    \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 472, 472, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 472, 472, 128)     131200    \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 944, 944, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 944, 944, 2)       1026      \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 1888, 1888, 2)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 788,994\n",
      "Trainable params: 788,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = mode()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "137/137 - 460s - loss: 0.0027 - accuracy: 0.5036 - 460s/epoch - 3s/step\n",
      "Epoch 2/60\n",
      "137/137 - 448s - loss: 0.0027 - accuracy: 0.4404 - 448s/epoch - 3s/step\n",
      "Epoch 3/60\n",
      "137/137 - 449s - loss: 0.0027 - accuracy: 0.4616 - 449s/epoch - 3s/step\n",
      "Epoch 4/60\n",
      "137/137 - 448s - loss: 0.0027 - accuracy: 0.4378 - 448s/epoch - 3s/step\n",
      "Epoch 5/60\n",
      "137/137 - 446s - loss: 0.0027 - accuracy: 0.4484 - 446s/epoch - 3s/step\n",
      "Epoch 6/60\n",
      "137/137 - 447s - loss: 0.0027 - accuracy: 0.4422 - 447s/epoch - 3s/step\n",
      "Epoch 7/60\n",
      "137/137 - 446s - loss: 0.0027 - accuracy: 0.4575 - 446s/epoch - 3s/step\n",
      "Epoch 8/60\n",
      "137/137 - 451s - loss: 0.0027 - accuracy: 0.4764 - 451s/epoch - 3s/step\n",
      "Epoch 9/60\n",
      "137/137 - 447s - loss: 0.0027 - accuracy: 0.4720 - 447s/epoch - 3s/step\n",
      "Epoch 10/60\n",
      "137/137 - 445s - loss: 0.0027 - accuracy: 0.5193 - 445s/epoch - 3s/step\n",
      "Epoch 11/60\n",
      "137/137 - 446s - loss: 0.0027 - accuracy: 0.4805 - 446s/epoch - 3s/step\n",
      "Epoch 12/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.4959 - 446s/epoch - 3s/step\n",
      "Epoch 13/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5579 - 447s/epoch - 3s/step\n",
      "Epoch 14/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5747 - 446s/epoch - 3s/step\n",
      "Epoch 15/60\n",
      "137/137 - 450s - loss: 0.0026 - accuracy: 0.5374 - 450s/epoch - 3s/step\n",
      "Epoch 16/60\n",
      "137/137 - 449s - loss: 0.0027 - accuracy: 0.5165 - 449s/epoch - 3s/step\n",
      "Epoch 17/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5521 - 446s/epoch - 3s/step\n",
      "Epoch 18/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5425 - 449s/epoch - 3s/step\n",
      "Epoch 19/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5563 - 447s/epoch - 3s/step\n",
      "Epoch 20/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5658 - 446s/epoch - 3s/step\n",
      "Epoch 21/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5573 - 446s/epoch - 3s/step\n",
      "Epoch 22/60\n",
      "137/137 - 450s - loss: 0.0026 - accuracy: 0.5606 - 450s/epoch - 3s/step\n",
      "Epoch 23/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5533 - 448s/epoch - 3s/step\n",
      "Epoch 24/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5630 - 447s/epoch - 3s/step\n",
      "Epoch 25/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5676 - 447s/epoch - 3s/step\n",
      "Epoch 26/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5670 - 449s/epoch - 3s/step\n",
      "Epoch 27/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5516 - 447s/epoch - 3s/step\n",
      "Epoch 28/60\n",
      "137/137 - 450s - loss: 0.0026 - accuracy: 0.5819 - 450s/epoch - 3s/step\n",
      "Epoch 29/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5608 - 446s/epoch - 3s/step\n",
      "Epoch 30/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5751 - 447s/epoch - 3s/step\n",
      "Epoch 31/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5678 - 447s/epoch - 3s/step\n",
      "Epoch 32/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5497 - 448s/epoch - 3s/step\n",
      "Epoch 33/60\n",
      "137/137 - 450s - loss: 0.0026 - accuracy: 0.5674 - 450s/epoch - 3s/step\n",
      "Epoch 34/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5689 - 447s/epoch - 3s/step\n",
      "Epoch 35/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5740 - 448s/epoch - 3s/step\n",
      "Epoch 36/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5560 - 449s/epoch - 3s/step\n",
      "Epoch 37/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5738 - 448s/epoch - 3s/step\n",
      "Epoch 38/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5681 - 448s/epoch - 3s/step\n",
      "Epoch 39/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5679 - 446s/epoch - 3s/step\n",
      "Epoch 40/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5553 - 449s/epoch - 3s/step\n",
      "Epoch 41/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5399 - 449s/epoch - 3s/step\n",
      "Epoch 42/60\n",
      "137/137 - 450s - loss: 0.0026 - accuracy: 0.5579 - 450s/epoch - 3s/step\n",
      "Epoch 43/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5759 - 448s/epoch - 3s/step\n",
      "Epoch 44/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5689 - 448s/epoch - 3s/step\n",
      "Epoch 45/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5705 - 447s/epoch - 3s/step\n",
      "Epoch 46/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5739 - 447s/epoch - 3s/step\n",
      "Epoch 47/60\n",
      "137/137 - 447s - loss: 0.0026 - accuracy: 0.5693 - 447s/epoch - 3s/step\n",
      "Epoch 48/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5736 - 449s/epoch - 3s/step\n",
      "Epoch 49/60\n",
      "137/137 - 450s - loss: 0.0026 - accuracy: 0.5739 - 450s/epoch - 3s/step\n",
      "Epoch 50/60\n",
      "137/137 - 449s - loss: 0.0026 - accuracy: 0.5801 - 449s/epoch - 3s/step\n",
      "Epoch 51/60\n",
      "137/137 - 446s - loss: 0.0026 - accuracy: 0.5696 - 446s/epoch - 3s/step\n",
      "Epoch 52/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5958 - 448s/epoch - 3s/step\n",
      "Epoch 53/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5799 - 448s/epoch - 3s/step\n",
      "Epoch 54/60\n",
      "137/137 - 448s - loss: 0.0026 - accuracy: 0.5744 - 448s/epoch - 3s/step\n",
      "Epoch 55/60\n",
      "137/137 - 449s - loss: 0.0025 - accuracy: 0.5742 - 449s/epoch - 3s/step\n",
      "Epoch 56/60\n",
      "137/137 - 449s - loss: 0.0025 - accuracy: 0.5743 - 449s/epoch - 3s/step\n",
      "Epoch 57/60\n",
      "137/137 - 448s - loss: 0.0025 - accuracy: 0.5639 - 448s/epoch - 3s/step\n",
      "Epoch 58/60\n",
      "137/137 - 448s - loss: 0.0025 - accuracy: 0.5386 - 448s/epoch - 3s/step\n",
      "Epoch 59/60\n",
      "137/137 - 448s - loss: 0.0025 - accuracy: 0.5686 - 448s/epoch - 3s/step\n",
      "Epoch 60/60\n",
      "137/137 - 449s - loss: 0.0025 - accuracy: 0.5636 - 449s/epoch - 3s/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "history = model1.fit(train_data, batch_size = batch_size, epochs = epochs, verbose = 2)  # add validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_tf_F60\\assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'my_model_tf_F60'\n",
    "model1.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "#reconstructed_model = keras.models.load_model(\"my_model_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"C:/Study/Semester2/Machine Learning/ML - Yes Photos/1900s_loose_bw_0036_mom.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_img_test(img_path):\n",
    "    imgRGB = cv2.imread(img_path)\n",
    "    imgBGR = np.flip(imgRGB, -1)\n",
    "    \n",
    "    #check the image category by 'shape' function\n",
    "    image_size_category = shape(imgBGR) #imgRGB\n",
    "    #print(\"image size determined!\")\n",
    "\n",
    "    if image_size_category <1:\n",
    "        raise Exception(\"Your image is too small to be used\")\n",
    "    elif image_size_category >4:\n",
    "        raise Exception(\"Your image is too big to be used\")\n",
    "\n",
    "    #print(\"image PCA started!\")\n",
    "    #image_pca = pca_rgb(imgRGB, image_size_category) \n",
    "    RGB_compressed = pca_rgb(imgBGR, image_size_category) #imgRGB, image_size_category\n",
    "    #RGB_compressed[400][400]\n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(RGB_compressed)\n",
    "    \n",
    "    print(\"image is padded\")\n",
    "    padded_image = rgb_pad(RGB_compressed)\n",
    "    #padded_image[1000][1000]\n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(padded_image)\n",
    "    \n",
    "    #image_pca = np.float32((1.0/255)*image_pca) # #The rgb_compressed come out in RGB scaled data already\n",
    "    print(\"image converted to LAB\")\n",
    "    padded_LAB = cv2.cvtColor(padded_image, cv2.COLOR_RGB2Lab) #convert padded RGB compressed to LAB\n",
    "    padded_LAB = padded_LAB/np.amax(padded_LAB) #scaled to -1/1\n",
    "    #imgLAB = np.clip(imgLAB, 0, 1)\n",
    "\n",
    "    \n",
    "    #separate L and AB color channels\n",
    "    Y = padded_LAB[:, :,1:]\n",
    "    #Y = Y / 128 #comment out when show predicted\n",
    "    #Y = Y.tolist()\n",
    "    X = padded_LAB[:, :, 0] #.tolist()\n",
    "    #print(X[1000])\n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(X)\n",
    "    \n",
    "    #this is in sample code and idk why\n",
    "    \n",
    "    X = X.reshape(1, 1888, 1888, 1) #comment out when show predicted\n",
    "    Y = Y.reshape(1, 1888, 1888, 2) #comment out when show predicted\n",
    "    \n",
    "    print(\"image processed\")\n",
    "\n",
    "    return Y, X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CL, BW = prep_img_test(test_path)\n",
    "#test_data = tf.data.Dataset.from_tensor_slices(BW)\n",
    "test_predict = model1.predict(BW) #what shape does the prediction takes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predict.shape # use this to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW.shape # use this to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge with d stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_reshaped = test_predict[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predict_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_reshaped[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_predict_reshaped[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_predict_reshaped[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW_reshaped  = BW[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BW_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(BW_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_LAB = np.dstack((BW_reshaped, test_predict_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_LAB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_merged_LAB[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_merged_LAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_merged_converted = color.Lab2rgb(test_merged)\n",
    "test_merged_rgb = test_merged_rgb*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_merged_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_rgb = cv2.cvtColor(test_merged, cv2.COLOR_Lab2RGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_merged_rgb[0][0] # this is weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_merged_rgb_scaled = (test_merged_rgb/255).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(test_merged_rgb)\n",
    "plt.imshow(test_merged_rgb_scaled )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('result1.jpg', test_merged_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a way to merge the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pastes predicted AB to RGB blank canvas\n",
    "canvas = np.zeros((1888,1888,3))\n",
    "canvas[:,:,0] = BW[0][:,:,0]\n",
    "canvas[:,:,1:] =test_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert AB (in RGB space) to rgb photo\n",
    "rgb_converted = color.lab2rgb(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_2rgb = cv2.cvtColor(canvas, cv2.COLOR_RGB2Lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_to = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path1 = 'C:/Study/Semester2/Machine Learning/ML - Yes Photos/1900s_loose_bw_0036_mom.jpg'\n",
    "Y01, X01 = prep_img(img_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X01[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show AB channel of the image\n",
    "plt.imshow(X01) #X01[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X01 = pd.DataFrame(X01[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y01 = pd.DataFrame(Y01[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "db6bc5cd-12ac-4fa4-b95f-4604d6441ef4",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
