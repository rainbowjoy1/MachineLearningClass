{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5a8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731c6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model #added\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, UpSampling2D, LayerNormalization, concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.image import resize\n",
    "from skimage import data, io,color\n",
    "from skimage.io import imread_collection #loads a collection of images\n",
    "from skimage.io import imread, imshow\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f61c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = 'C:/Study/Semester2/Machine Learning/smaller2/boy1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2c3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#from IPython import embed # don't use yet\n",
    "\n",
    "def load_img(img_path):\n",
    "\tout_np = np.asarray(Image.open(img_path))\n",
    "\tif(out_np.ndim==2):\n",
    "\t\tout_np = np.tile(out_np[:,:,None],3)\n",
    "\treturn out_np\n",
    "\n",
    "def resize_img(img, HW=(256,256), resample=3):\n",
    "\treturn np.asarray(Image.fromarray(img).resize((HW[1],HW[0]), resample=resample))\n",
    "\n",
    "def preprocess_img(img_rgb_orig, HW=(256,256), resample=3):\n",
    "\t# return original size L and resized L as torch Tensors\n",
    "\timg_rgb_rs = resize_img(img_rgb_orig, HW=HW, resample=resample)\n",
    "\t\n",
    "\timg_lab_orig = color.rgb2lab(img_rgb_orig)\n",
    "\timg_lab_rs = color.rgb2lab(img_rgb_rs)\n",
    "\n",
    "\timg_l_orig = img_lab_orig[:,:,0]\n",
    "\timg_ab_orig = img_lab_orig[:,:,1:]   \n",
    "\timg_l_rs = img_lab_rs[:,:,0]\n",
    "\timg_ab_rs = img_lab_rs[:,:,1:]\n",
    "\t#tens_orig_l = torch.Tensor(img_l_orig)[None,None,:,:]\n",
    "\t#tens_rs_l = torch.Tensor(img_l_rs)[None,None,:,:]\n",
    "\ttens_orig_l = tf.convert_to_tensor(img_l_orig)[None,None,:,:]\n",
    "\ttens_orig_ab = tf.convert_to_tensor(img_ab_orig)[None,None,:,:]\n",
    "\ttens_rs_l = tf.convert_to_tensor(img_l_rs)[None,None,:,:]\n",
    "\ttens_rs_ab = tf.convert_to_tensor(img_ab_rs)[None,None,:,:]  \n",
    "\treturn tens_orig_l, tens_rs_l, tens_orig_ab,tens_rs_ab\n",
    "\n",
    "def postprocess_tens(tens_orig_l, out_ab, mode='bilinear'):\n",
    "\t# tens_orig_l \t1 x 1 x H_orig x W_orig\n",
    "\t# out_ab \t\t1 x 2 x H x W\n",
    "\n",
    "\tHW_orig = tens_orig_l.shape[2:]\n",
    "\tprint(HW_orig)\n",
    "\tHW = out_ab.shape[2:]\n",
    "\tprint(HW)\n",
    "\t# call resize function if needed\n",
    "\tif(HW_orig[0]!=HW[0] or HW_orig[1]!=HW[1]):\n",
    "\t\tout_ab_orig = resize(out_ab, size=HW_orig) #F.interpolate(out_ab, size=HW_orig, mode='bilinear')\n",
    "\telse:\n",
    "\t\tout_ab_orig = out_ab\n",
    "\n",
    "\tout_lab_orig = concatenate((tens_orig_l, out_ab_orig)) #torch.cat((tens_orig_l, out_ab_orig), dim=1)\n",
    "\treturn color.lab2rgb(out_lab_orig.data.cpu().numpy()[0,...].transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9ac263",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img_org = load_img(org_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f7496a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (750, 600, 3) 0 255\n"
     ]
    }
   ],
   "source": [
    "print('original shape:',  np_img_org.shape, np.min(np_img_org), np.max(np_img_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117c5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_orig_l, tens_rs_l, tens_orig_ab,tens_rs_ab = preprocess_img(np_img_org, HW=(256,256), resample=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "565cd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 750, 600) (1, 1, 256, 256) (1, 1, 750, 600, 2) (1, 1, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print(tens_orig_l.shape, tens_rs_l.shape, tens_orig_ab.shape,tens_rs_ab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea68d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(): \n",
    "    model2 = Sequential([\n",
    "        #encoder\n",
    "        Conv2D(128, 2, strides = 1, padding = \"same\", activation = \"relu\", input_shape= (1,256, 256)), #testing shape changes\n",
    "        Conv2D(256, 2, strides = 1, padding = \"same\", activation = \"relu\"), \n",
    "        Conv2D(512, 2, strides = 1, padding = \"same\", activation = \"relu\"), #filter = 256\n",
    "        \n",
    "        #decoder\n",
    "  \n",
    "        Conv2D(256, 2, padding = \"same\", activation = \"relu\"), \n",
    "        \n",
    "        Conv2D(128, 2, padding = \"same\", activation = \"relu\"), \n",
    "\n",
    "        Conv2D(256, 2, padding = \"same\", activation = \"softmax\"),\n",
    "\n",
    "    ])\n",
    "    model2.compile(optimizer =\"adam\", loss = \"mse\", metrics = [\"accuracy\"])\n",
    "    ##LayerNormalization()\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73e4a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 1, 256, 128)       131200    \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 1, 256, 256)       131328    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 256, 512)       524800    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 256, 256)       524544    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 1, 256, 128)       131200    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 256, 256)       131328    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,574,400\n",
      "Trainable params: 1,574,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = mode() \n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d86f215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 256 and 2 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/conv2d_5/Softmax, Cast)' with input shapes: [?,1,256,256], [?,1,256,256,2].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-483ec4ea8571>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtens_rs_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtens_rs_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# add validation_split = 0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\midyr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1329, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 256 and 2 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/conv2d_5/Softmax, Cast)' with input shapes: [?,1,256,256], [?,1,256,256,2].\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "history = model2.fit(tens_rs_l, tens_rs_ab, epochs = epochs, verbose = 2)  # add validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "caca8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('Zhang-ours.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c1c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_66 (Conv2D)          (None, 1, 256, 1)         1048577   \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 1, 256, 64)        262208    \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 1, 256, 256)       65792     \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 1, 256, 256)       262400    \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 1, 256, 128)       131200    \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 1, 256, 2)         1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,771,203\n",
      "Trainable params: 1,771,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load the model\n",
    "savedModel=load_model('Zhang-ours.h5')\n",
    "savedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3345ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = savedModel.predict(tens_rs_l) #what shape does the prediction takes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745d393f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 256, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5eb791e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([750, 600])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_orig_l.shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fac810ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 600)\n",
      "(256, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=((1, 1, 750, 600), (1, 750, 600, 2))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-9c08e8b8d8c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout_img_eccv16\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostprocess_tens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtens_orig_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-2d206fac7f65>\u001b[0m in \u001b[0;36mpostprocess_tens\u001b[1;34m(tens_orig_l, out_ab, mode)\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mout_ab_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_ab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mout_lab_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtens_orig_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ab_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#torch.cat((tens_orig_l, out_ab_orig), dim=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlab2rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_lab_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m   \"\"\"\n\u001b[1;32m--> 968\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    526\u001b[0m             shape[axis] for shape in shape_set if shape[axis] is not None)\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=((1, 1, 750, 600), (1, 750, 600, 2))"
     ]
    }
   ],
   "source": [
    "out_img_eccv16 = postprocess_tens(tens_orig_l, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfdcc15a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ed3697e63a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase_color\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mECCVGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseColor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "import numpy as np\n",
    "from IPython import embed\n",
    "\n",
    "from .base_color import *\n",
    "\n",
    "class ECCVGenerator(BaseColor):\n",
    "    def __init__(self, norm_layer=nn.BatchNorm2d):\n",
    "        super(ECCVGenerator, self).__init__()\n",
    "\n",
    "        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[norm_layer(64),]\n",
    "\n",
    "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[norm_layer(128),]\n",
    "\n",
    "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[norm_layer(256),]\n",
    "\n",
    "        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[norm_layer(512),]\n",
    "\n",
    "        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[norm_layer(512),]\n",
    "\n",
    "        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[norm_layer(512),]\n",
    "\n",
    "        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[norm_layer(512),]\n",
    "\n",
    "        model8=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "\n",
    "        model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),]\n",
    "\n",
    "        self.model1 = nn.Sequential(*model1)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        self.model3 = nn.Sequential(*model3)\n",
    "        self.model4 = nn.Sequential(*model4)\n",
    "        self.model5 = nn.Sequential(*model5)\n",
    "        self.model6 = nn.Sequential(*model6)\n",
    "        self.model7 = nn.Sequential(*model7)\n",
    "        self.model8 = nn.Sequential(*model8)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
    "        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "\n",
    "    def forward(self, input_l):\n",
    "        conv1_2 = self.model1(self.normalize_l(input_l))\n",
    "        conv2_2 = self.model2(conv1_2)\n",
    "        conv3_3 = self.model3(conv2_2)\n",
    "        conv4_3 = self.model4(conv3_3)\n",
    "        conv5_3 = self.model5(conv4_3)\n",
    "        conv6_3 = self.model6(conv5_3)\n",
    "        conv7_3 = self.model7(conv6_3)\n",
    "        conv8_3 = self.model8(conv7_3)\n",
    "        out_reg = self.model_out(self.softmax(conv8_3))\n",
    "\n",
    "        return self.unnormalize_ab(self.upsample4(out_reg))\n",
    "\n",
    "def eccv16(pretrained=True):\n",
    "\tmodel = ECCVGenerator()\n",
    "\tif(pretrained):\n",
    "\t\timport torch.utils.model_zoo as model_zoo\n",
    "\t\tmodel.load_state_dict(model_zoo.load_url('https://colorizers.s3.us-east-2.amazonaws.com/colorization_release_v2-9b330a0b.pth',map_location='cpu',check_hash=True))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d8109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
